{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (4.10.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from beautifulsoup4) (2.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: stop-words in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (2018.7.23)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting fr-core-news-md==3.2.0\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/fr_core_news_md-3.2.0/fr_core_news_md-3.2.0-py3-none-any.whl (46.9 MB)\n",
      "Requirement already satisfied: spacy<3.3.0,>=3.2.0 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from fr-core-news-md==3.2.0) (3.2.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (0.4.1)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (8.0.13)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (3.7.4.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (2.4.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (1.19.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (0.8.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (2.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (1.0.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (3.0.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (3.0.8)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (2.25.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (0.4.0)\n",
      "Requirement already satisfied: jinja2 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (3.0.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (4.60.0)\n",
      "Requirement already satisfied: setuptools in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (41.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (20.9)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (1.0.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (0.6.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (3.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (5.2.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (1.26.6)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (3.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (8.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0.0rc2 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from jinja2->spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (3.10.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_md')\n",
      "Requirement already satisfied: python_Levenshtein==0.12.0 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (0.12.0)\n",
      "Requirement already satisfied: setuptools in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from python_Levenshtein==0.12.0) (41.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install beautifulsoup4\n",
    "# %pip install stop-words\n",
    "# !python -m spacy download fr_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import lru_cache\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import OrderedDict\n",
    "import nltk\n",
    "import Levenshtein\n",
    "from nltk.tokenize import word_tokenize\n",
    "from stop_words import get_stop_words\n",
    "stopwords = get_stop_words('french')\n",
    "# from nltk.corpus import stopwords\n",
    "# stopwords = stopwords.words('french')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_lines(filepath):\n",
    "    with Path(filepath).open('r') as f:\n",
    "        for line in f:\n",
    "            yield line.strip('\\n').strip()\n",
    "def read_lines(filepath):\n",
    "    return ' '.join(yield_lines(filepath))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files:  407\n",
      "100\n",
      "{'ml', 'ngr', 'dm', 'cc', 'eb', 'jd', 'ak', 'ep', 'oi'}\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100]\n"
     ]
    }
   ],
   "source": [
    "REPO_DIR = Path('..').resolve()\n",
    "DATA_DIR = REPO_DIR / 'resources/dataset/FIXED_ANNOTATED_CLINICALCASES'\n",
    "\n",
    "filepaths = sorted(list(DATA_DIR.glob('*.xml')))\n",
    "print('Number of files: ', len(filepaths))\n",
    "\n",
    "files = set()\n",
    "annotators = set()\n",
    "for filepath in filepaths:\n",
    "    chunks = filepath.stem.split('-')\n",
    "    if len(chunks) > 2:\n",
    "        annotators.add(chunks[0])\n",
    "        files.add(int(chunks[1]))\n",
    "\n",
    "\n",
    "print(len(files))\n",
    "print(annotators)\n",
    "print(sorted(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml 1\n",
      "ngr 100\n",
      "dm 1\n",
      "cc 1\n",
      "eb 1\n",
      "jd 3\n",
      "ak 100\n",
      "ep 100\n",
      "oi 100\n"
     ]
    }
   ],
   "source": [
    "# annotators annotated number of files\n",
    "for annotator in annotators:\n",
    "    print(annotator, len(set([filepath.stem for filepath in filepaths if filepath.stem.startswith(annotator)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/kim/Sync/workspace/Lille/LexSimMed/FIXED_ANNOTATED_CLINICALCASES/ak-1-content.xml')"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = filepaths[0]\n",
    "filepath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "with filepath.open('r') as f:\n",
    "    soup = BeautifulSoup(f.read())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "def tokenize(text, lang='french'):\n",
    "    return word_tokenize(text, language=lang)\n",
    "\n",
    "@lru_cache(maxsize=1)\n",
    "def get_spacy_model():\n",
    "    model = 'fr_core_news_md'\n",
    "    if not spacy.util.is_package(model):\n",
    "        spacy.cli.download(model)\n",
    "        spacy.cli.link(model, model, force=True,\n",
    "                       model_path=spacy.util.get_package_path(model))\n",
    "    return spacy.load(model)  # python -m spacy download en_core_web_sm`\n",
    "\n",
    "def to_lemmas(word):\n",
    "    nlp = get_spacy_model()\n",
    "    doc = nlp(word.lower())\n",
    "    lemmas = []\n",
    "    for token in doc:\n",
    "        lemmas.append(token.lemma_.strip(\"'\"))\n",
    "    return lemmas\n",
    "\n",
    "@lru_cache(maxsize=4048)\n",
    "def is_stopword(word):\n",
    "    tokens = to_lemmas(word)\n",
    "    return len([token for token in tokens if token not in stopwords]) == 0\n",
    "\n",
    "# print(len(stopwords))\n",
    "# print(stopwords)\n",
    "print(is_stopword('avec eux'))\n",
    "print(is_stopword('est une fille'))\n",
    "print(is_stopword(\"n'est\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 407/407 [00:33<00:00, 12.17it/s]\n"
     ]
    }
   ],
   "source": [
    "@lru_cache(maxsize=1)\n",
    "def get_sentence_segment_model():\n",
    "    from spacy.lang.fr import French\n",
    "\n",
    "    nlp_fr = French()  # just the language with no pipeline\n",
    "    nlp_fr.add_pipe(\"sentencizer\")\n",
    "    return nlp_fr\n",
    "    \n",
    "LABELS = ['par-défaut', 'ne-connais-pas', 'pas-sur-de-comprendre']\n",
    "\n",
    "def process(filepath):\n",
    "    doc = []    \n",
    "    with filepath.open('r') as f:\n",
    "        soup = BeautifulSoup(f.read())\n",
    "        for p in soup.find_all('text:p'):\n",
    "            text = p.getText() \n",
    "            target_words = re.findall(r\"\\[(.*?)\\]\", text)\n",
    "            \n",
    "            # skip target text that contains only stopwords\n",
    "            target_words = [f'{w}' for w in target_words if not is_stopword(w)]\n",
    "            # print(target_words)\n",
    "\n",
    "            word_dict = OrderedDict({word: LABELS[0] for word in target_words if word})\n",
    "            # print(dict)\n",
    "            # print(text)\n",
    "            text_spans = p.find_all('text:span')\n",
    "            for span in text_spans:\n",
    "                label = span.get('text:style-name')\n",
    "                # print(span.getText(), label)\n",
    "                if label in LABELS:\n",
    "                    target_text = span.getText()\n",
    "                    difficult_words = re.findall(r\"\\[(.*?)\\]\", target_text)\n",
    "                    for difficult_word in difficult_words:\n",
    "                        # print(difficult_word)\n",
    "                        word_dict[difficult_word] = label\n",
    "\n",
    "            text = re.sub(r'[\\[\\]]', '', text) # remove brackets\n",
    "            nlp_fr = get_sentence_segment_model()\n",
    "            nlp_doc = nlp_fr(text)\n",
    "\n",
    "            for word in word_dict:\n",
    "                \n",
    "                item = {}\n",
    "                item['annotator_file'] = filepath.stem.replace('-content','')\n",
    "                item['paragraph'] = text # remove brackets\n",
    "                \n",
    "                # add sentence-level text\n",
    "                item['sentence'] = ''\n",
    "                for sentence in nlp_doc.sents:\n",
    "                    # print(word, \" :: \", sentence, \" : \", word in sentence.text)\n",
    "                    if re.search(re.escape(word), sentence.text, re.IGNORECASE):\n",
    "                        item['sentence'] = sentence.text\n",
    "                        break\n",
    "\n",
    "                item['target'] = word\n",
    "                item['label'] = word_dict[word]\n",
    "\n",
    "                doc.append(item)\n",
    "    return doc\n",
    "    \n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "pool = multiprocessing.Pool(processes=multiprocessing.cpu_count())\n",
    "mapped_values = list(tqdm(pool.imap(process, filepaths), total=len(filepaths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame([value for values in mapped_values for value in values])\n",
    "data = data[data['sentence'] != ''] # drop rows with empty sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotator_file</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>sentence</th>\n",
       "      <th>target</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ak-1</td>\n",
       "      <td>Il s'agit d'une femme de 32 ans d'origine ghan...</td>\n",
       "      <td>Il s'agit d'une femme de 32 ans d'origine ghan...</td>\n",
       "      <td>s'agit</td>\n",
       "      <td>par-défaut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ak-1</td>\n",
       "      <td>Il s'agit d'une femme de 32 ans d'origine ghan...</td>\n",
       "      <td>Il s'agit d'une femme de 32 ans d'origine ghan...</td>\n",
       "      <td>d'une femme</td>\n",
       "      <td>par-défaut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ak-1</td>\n",
       "      <td>Il s'agit d'une femme de 32 ans d'origine ghan...</td>\n",
       "      <td>Il s'agit d'une femme de 32 ans d'origine ghan...</td>\n",
       "      <td>de 32 ans</td>\n",
       "      <td>par-défaut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ak-1</td>\n",
       "      <td>Il s'agit d'une femme de 32 ans d'origine ghan...</td>\n",
       "      <td>Il s'agit d'une femme de 32 ans d'origine ghan...</td>\n",
       "      <td>d'origine ghanéenne enceinte de 14 semaines</td>\n",
       "      <td>par-défaut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ak-1</td>\n",
       "      <td>Il s'agit d'une femme de 32 ans d'origine ghan...</td>\n",
       "      <td>Elle présente des vomissements depuis le début...</td>\n",
       "      <td>présente</td>\n",
       "      <td>par-défaut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51858</th>\n",
       "      <td>oi-99</td>\n",
       "      <td>De principe , un traitement antituberculeux pa...</td>\n",
       "      <td>De principe , un traitement antituberculeux pa...</td>\n",
       "      <td>a été instauré</td>\n",
       "      <td>par-défaut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51859</th>\n",
       "      <td>oi-99</td>\n",
       "      <td>De principe , un traitement antituberculeux pa...</td>\n",
       "      <td>De principe , un traitement antituberculeux pa...</td>\n",
       "      <td>pour 2 mois</td>\n",
       "      <td>par-défaut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51860</th>\n",
       "      <td>oi-99</td>\n",
       "      <td>De principe , un traitement antituberculeux pa...</td>\n",
       "      <td>De principe , un traitement antituberculeux pa...</td>\n",
       "      <td>relayé</td>\n",
       "      <td>par-défaut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51861</th>\n",
       "      <td>oi-99</td>\n",
       "      <td>De principe , un traitement antituberculeux pa...</td>\n",
       "      <td>De principe , un traitement antituberculeux pa...</td>\n",
       "      <td>par une bithérapie</td>\n",
       "      <td>pas-sur-de-comprendre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51862</th>\n",
       "      <td>oi-99</td>\n",
       "      <td>De principe , un traitement antituberculeux pa...</td>\n",
       "      <td>De principe , un traitement antituberculeux pa...</td>\n",
       "      <td>pendant 4 mois</td>\n",
       "      <td>par-défaut</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51825 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      annotator_file                                          paragraph  \\\n",
       "0               ak-1  Il s'agit d'une femme de 32 ans d'origine ghan...   \n",
       "1               ak-1  Il s'agit d'une femme de 32 ans d'origine ghan...   \n",
       "2               ak-1  Il s'agit d'une femme de 32 ans d'origine ghan...   \n",
       "3               ak-1  Il s'agit d'une femme de 32 ans d'origine ghan...   \n",
       "4               ak-1  Il s'agit d'une femme de 32 ans d'origine ghan...   \n",
       "...              ...                                                ...   \n",
       "51858          oi-99  De principe , un traitement antituberculeux pa...   \n",
       "51859          oi-99  De principe , un traitement antituberculeux pa...   \n",
       "51860          oi-99  De principe , un traitement antituberculeux pa...   \n",
       "51861          oi-99  De principe , un traitement antituberculeux pa...   \n",
       "51862          oi-99  De principe , un traitement antituberculeux pa...   \n",
       "\n",
       "                                                sentence  \\\n",
       "0      Il s'agit d'une femme de 32 ans d'origine ghan...   \n",
       "1      Il s'agit d'une femme de 32 ans d'origine ghan...   \n",
       "2      Il s'agit d'une femme de 32 ans d'origine ghan...   \n",
       "3      Il s'agit d'une femme de 32 ans d'origine ghan...   \n",
       "4      Elle présente des vomissements depuis le début...   \n",
       "...                                                  ...   \n",
       "51858  De principe , un traitement antituberculeux pa...   \n",
       "51859  De principe , un traitement antituberculeux pa...   \n",
       "51860  De principe , un traitement antituberculeux pa...   \n",
       "51861  De principe , un traitement antituberculeux pa...   \n",
       "51862  De principe , un traitement antituberculeux pa...   \n",
       "\n",
       "                                            target                  label  \n",
       "0                                           s'agit             par-défaut  \n",
       "1                                      d'une femme             par-défaut  \n",
       "2                                        de 32 ans             par-défaut  \n",
       "3      d'origine ghanéenne enceinte de 14 semaines             par-défaut  \n",
       "4                                         présente             par-défaut  \n",
       "...                                            ...                    ...  \n",
       "51858                               a été instauré             par-défaut  \n",
       "51859                                  pour 2 mois             par-défaut  \n",
       "51860                                       relayé             par-défaut  \n",
       "51861                           par une bithérapie  pas-sur-de-comprendre  \n",
       "51862                               pendant 4 mois             par-défaut  \n",
       "\n",
       "[51825 rows x 5 columns]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv( REPO_DIR / 'resources/dataset/data_all_annotators.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge all data based on annotators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(REPO_DIR / 'resources/dataset/data_all_annotators.csv')\n",
    "\n",
    "# data['label'] = data['label'].replace('pas-sur-de-comprendre', 'ne-connais-pas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>la voix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>les metabolites</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>à type d'incontinence urinaire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>et de myopie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>au total trois mois</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9704</th>\n",
       "      <td>à 5 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9705</th>\n",
       "      <td>avec étude histologique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9706</th>\n",
       "      <td>lors de cette perfusion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9707</th>\n",
       "      <td>de la nicotine,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9708</th>\n",
       "      <td>de métastase lymphonodale pelvienne</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9709 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        0\n",
       "0                                 la voix\n",
       "1                         les metabolites\n",
       "2          à type d'incontinence urinaire\n",
       "3                            et de myopie\n",
       "4                     au total trois mois\n",
       "...                                   ...\n",
       "9704                                à 5 %\n",
       "9705              avec étude histologique\n",
       "9706              lors de cette perfusion\n",
       "9707                      de la nicotine,\n",
       "9708  de métastase lymphonodale pelvienne\n",
       "\n",
       "[9709 rows x 1 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words = data['target'].unique()\n",
    "# unique_words = data[data['label'] == 'ne-connais-pas']['target'].unique()\n",
    "unique_words = set([word.lower() for word in unique_words])\n",
    "# pd.DataFrame(unique_words).to_csv('unique_words.csv', index=False)\n",
    "pd.DataFrame(unique_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9709/9709 [00:26<00:00, 359.71it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotator_file</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>sentence</th>\n",
       "      <th>target</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8642</th>\n",
       "      <td>ak-57</td>\n",
       "      <td>En novembre 2002 , étant donné la fréquence du...</td>\n",
       "      <td>Après trois mois de ce régime , on note une ne...</td>\n",
       "      <td>la voix</td>\n",
       "      <td>par-défaut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11890</th>\n",
       "      <td>ak-89</td>\n",
       "      <td>Une femme de 29 ans est victime d'agression se...</td>\n",
       "      <td>Du GHB est retrouvé dans l'urine au taux de 4 ...</td>\n",
       "      <td>les metabolites</td>\n",
       "      <td>ne-connais-pas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>ak-10</td>\n",
       "      <td>Madame Nicole R., 63 ans, a été hospitalisée p...</td>\n",
       "      <td>A l'interrogatoire, il existait des troubles d...</td>\n",
       "      <td>à type d'incontinence urinaire</td>\n",
       "      <td>par-défaut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7061</th>\n",
       "      <td>ak-51</td>\n",
       "      <td>Le patient est traité pour une acné vulgaire ,...</td>\n",
       "      <td>Il souffre par ailleurs d'allergies saisonnièr...</td>\n",
       "      <td>et de myopie</td>\n",
       "      <td>ne-connais-pas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8006</th>\n",
       "      <td>ak-54</td>\n",
       "      <td>Au jour 0 , le jeune patient reçoit de l'acéta...</td>\n",
       "      <td>Les échanges plasmatiques pour ce patient ont ...</td>\n",
       "      <td>au total trois mois</td>\n",
       "      <td>par-défaut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>ak-1</td>\n",
       "      <td>Lors de la première visite médicale à 11 semai...</td>\n",
       "      <td>Une perfusion intraveineuse continue de soluti...</td>\n",
       "      <td>à 5 %</td>\n",
       "      <td>par-défaut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11462</th>\n",
       "      <td>ak-82</td>\n",
       "      <td>Mme L . K 50 ans , diabétique , est admise dan...</td>\n",
       "      <td>La biopsie avec étude histologique confirme le...</td>\n",
       "      <td>avec étude histologique</td>\n",
       "      <td>par-défaut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8026</th>\n",
       "      <td>ak-54</td>\n",
       "      <td>Le patient devait recevoir quatre doses de rit...</td>\n",
       "      <td>La dose totale reçue lors de cette perfusion a...</td>\n",
       "      <td>lors de cette perfusion</td>\n",
       "      <td>par-défaut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3029</th>\n",
       "      <td>ak-28</td>\n",
       "      <td>Le 12 février, Mademoiselle M., 36 ans, 64 kg,...</td>\n",
       "      <td>Du méprobamate, de l'acéprométazine, des benzo...</td>\n",
       "      <td>de la nicotine,</td>\n",
       "      <td>par-défaut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11473</th>\n",
       "      <td>ak-82</td>\n",
       "      <td>Mme L . K 50 ans , diabétique , est admise dan...</td>\n",
       "      <td>Le scanner abdomino-pelvien montre l'extension...</td>\n",
       "      <td>de métastase lymphonodale pelvienne</td>\n",
       "      <td>ne-connais-pas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9709 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      annotator_file                                          paragraph  \\\n",
       "8642           ak-57  En novembre 2002 , étant donné la fréquence du...   \n",
       "11890          ak-89  Une femme de 29 ans est victime d'agression se...   \n",
       "482            ak-10  Madame Nicole R., 63 ans, a été hospitalisée p...   \n",
       "7061           ak-51  Le patient est traité pour une acné vulgaire ,...   \n",
       "8006           ak-54  Au jour 0 , le jeune patient reçoit de l'acéta...   \n",
       "...              ...                                                ...   \n",
       "69              ak-1  Lors de la première visite médicale à 11 semai...   \n",
       "11462          ak-82  Mme L . K 50 ans , diabétique , est admise dan...   \n",
       "8026           ak-54  Le patient devait recevoir quatre doses de rit...   \n",
       "3029           ak-28  Le 12 février, Mademoiselle M., 36 ans, 64 kg,...   \n",
       "11473          ak-82  Mme L . K 50 ans , diabétique , est admise dan...   \n",
       "\n",
       "                                                sentence  \\\n",
       "8642   Après trois mois de ce régime , on note une ne...   \n",
       "11890  Du GHB est retrouvé dans l'urine au taux de 4 ...   \n",
       "482    A l'interrogatoire, il existait des troubles d...   \n",
       "7061   Il souffre par ailleurs d'allergies saisonnièr...   \n",
       "8006   Les échanges plasmatiques pour ce patient ont ...   \n",
       "...                                                  ...   \n",
       "69     Une perfusion intraveineuse continue de soluti...   \n",
       "11462  La biopsie avec étude histologique confirme le...   \n",
       "8026   La dose totale reçue lors de cette perfusion a...   \n",
       "3029   Du méprobamate, de l'acéprométazine, des benzo...   \n",
       "11473  Le scanner abdomino-pelvien montre l'extension...   \n",
       "\n",
       "                                    target           label  \n",
       "8642                               la voix      par-défaut  \n",
       "11890                      les metabolites  ne-connais-pas  \n",
       "482         à type d'incontinence urinaire      par-défaut  \n",
       "7061                          et de myopie  ne-connais-pas  \n",
       "8006                   au total trois mois      par-défaut  \n",
       "...                                    ...             ...  \n",
       "69                                   à 5 %      par-défaut  \n",
       "11462              avec étude histologique      par-défaut  \n",
       "8026               lors de cette perfusion      par-défaut  \n",
       "3029                       de la nicotine,      par-défaut  \n",
       "11473  de métastase lymphonodale pelvienne  ne-connais-pas  \n",
       "\n",
       "[9709 rows x 5 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "\n",
    "def data_selection(word):\n",
    "    fd = data[data['target'].str.lower() == word]\n",
    "    labels = fd['label'].to_list()\n",
    "    \n",
    "    # majority approach\n",
    "    # counter = Counter(labels)\n",
    "    # label = 'ne-connais-pas' if counter['ne-connais-pas'] >= counter['par-défaut'] else 'par-défaut'\n",
    "\n",
    "    # at least one ne-connais-pas approach\n",
    "    label = 'ne-connais-pas' if 'ne-connais-pas' in labels else 'par-défaut'\n",
    "\n",
    "    d = fd.iloc[0]\n",
    "    d['label'] = label\n",
    "    return d\n",
    "\n",
    "pool = multiprocessing.Pool(processes=multiprocessing.cpu_count())\n",
    "new_data = list(tqdm(pool.imap(data_selection, unique_words), total=len(unique_words)))\n",
    "\n",
    "\n",
    "new_data = pd.DataFrame(new_data)\n",
    "new_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3482, 5)\n",
      "(6227, 5)\n"
     ]
    }
   ],
   "source": [
    "# count each label\n",
    "print(new_data[new_data['label'] == 'ne-connais-pas'].shape)\n",
    "print(new_data[new_data['label'] == 'par-défaut'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save final data\n",
    "new_data.drop('annotator_file', inplace=True, axis=1)\n",
    "new_data.to_csv(REPO_DIR / 'resources/dataset/data.csv', index=False)\n",
    "new_data.to_excel(REPO_DIR / 'resources/dataset/data.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "08327656ff96552322a71a64f5ff759da69de14cc072a1bce0d6912743ec3a15"
  },
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('dev': pyenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
