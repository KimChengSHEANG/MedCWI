{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (4.10.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from beautifulsoup4) (2.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: stop-words in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (2018.7.23)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting fr-core-news-md==3.2.0\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/fr_core_news_md-3.2.0/fr_core_news_md-3.2.0-py3-none-any.whl (46.9 MB)\n",
      "Requirement already satisfied: spacy<3.3.0,>=3.2.0 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from fr-core-news-md==3.2.0) (3.2.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (0.4.1)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (8.0.13)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (3.7.4.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (2.4.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (1.19.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (0.8.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (2.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (1.0.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (3.0.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (3.0.8)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (2.25.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (0.4.0)\n",
      "Requirement already satisfied: jinja2 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (3.0.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (4.60.0)\n",
      "Requirement already satisfied: setuptools in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (41.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (20.9)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (1.0.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (0.6.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (3.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (5.2.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (1.26.6)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (3.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (8.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0.0rc2 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from jinja2->spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->fr-core-news-md==3.2.0) (3.10.1)\n",
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_md')\n",
      "Requirement already satisfied: python_Levenshtein==0.12.0 in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (0.12.0)\n",
      "Requirement already satisfied: setuptools in /home/kim/.pyenv/versions/3.7.5/envs/dev/lib/python3.7/site-packages (from python_Levenshtein==0.12.0) (41.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install beautifulsoup4\n",
    "# %pip install stop-words\n",
    "# !python -m spacy download fr_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import lru_cache\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import OrderedDict\n",
    "import nltk\n",
    "import Levenshtein\n",
    "from nltk.tokenize import word_tokenize\n",
    "from stop_words import get_stop_words\n",
    "stopwords = get_stop_words('french')\n",
    "# from nltk.corpus import stopwords\n",
    "# stopwords = stopwords.words('french')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_lines(filepath):\n",
    "    with Path(filepath).open('r') as f:\n",
    "        for line in f:\n",
    "            yield line.strip('\\n').strip()\n",
    "def read_lines(filepath):\n",
    "    return ' '.join(yield_lines(filepath))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files:  407\n",
      "100\n",
      "{'ml', 'ngr', 'dm', 'cc', 'eb', 'jd', 'ak', 'ep', 'oi'}\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100]\n"
     ]
    }
   ],
   "source": [
    "REPO_DIR = Path('..').resolve()\n",
    "DATA_DIR = REPO_DIR / 'resources/dataset/FIXED_ANNOTATED_CLINICALCASES'\n",
    "\n",
    "filepaths = sorted(list(DATA_DIR.glob('*.xml')))\n",
    "print('Number of files: ', len(filepaths))\n",
    "\n",
    "files = set()\n",
    "annotators = set()\n",
    "for filepath in filepaths:\n",
    "    chunks = filepath.stem.split('-')\n",
    "    if len(chunks) > 2:\n",
    "        annotators.add(chunks[0])\n",
    "        files.add(int(chunks[1]))\n",
    "\n",
    "\n",
    "print(len(files))\n",
    "print(annotators)\n",
    "print(sorted(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml 1\n",
      "ngr 100\n",
      "dm 1\n",
      "cc 1\n",
      "eb 1\n",
      "jd 3\n",
      "ak 100\n",
      "ep 100\n",
      "oi 100\n"
     ]
    }
   ],
   "source": [
    "# annotators annotated number of files\n",
    "for annotator in annotators:\n",
    "    print(annotator, len(set([filepath.stem for filepath in filepaths if filepath.stem.startswith(annotator)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/kim/Sync/workspace/Lille/LexSimMed/FIXED_ANNOTATED_CLINICALCASES/ak-1-content.xml')"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = filepaths[0]\n",
    "filepath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "with filepath.open('r') as f:\n",
    "    soup = BeautifulSoup(f.read())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "def tokenize(text, lang='french'):\n",
    "    return word_tokenize(text, language=lang)\n",
    "\n",
    "@lru_cache(maxsize=1)\n",
    "def get_spacy_model():\n",
    "    model = 'fr_core_news_md'\n",
    "    if not spacy.util.is_package(model):\n",
    "        spacy.cli.download(model)\n",
    "        spacy.cli.link(model, model, force=True,\n",
    "                       model_path=spacy.util.get_package_path(model))\n",
    "    return spacy.load(model)  # python -m spacy download en_core_web_sm`\n",
    "\n",
    "def to_lemmas(word):\n",
    "    nlp = get_spacy_model()\n",
    "    doc = nlp(word.lower())\n",
    "    lemmas = []\n",
    "    for token in doc:\n",
    "        lemmas.append(token.lemma_.strip(\"'\"))\n",
    "    return lemmas\n",
    "\n",
    "@lru_cache(maxsize=4048)\n",
    "def is_stopword(word):\n",
    "    tokens = to_lemmas(word)\n",
    "    return len([token for token in tokens if token not in stopwords]) == 0\n",
    "\n",
    "# print(len(stopwords))\n",
    "# print(stopwords)\n",
    "print(is_stopword('avec eux'))\n",
    "print(is_stopword('est une fille'))\n",
    "print(is_stopword(\"n'est\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 407/407 [00:33<00:00, 12.17it/s]\n"
     ]
    }
   ],
   "source": [
    "@lru_cache(maxsize=1)\n",
    "def get_sentence_segment_model():\n",
    "    from spacy.lang.fr import French\n",
    "\n",
    "    nlp_fr = French()  # just the language with no pipeline\n",
    "    nlp_fr.add_pipe(\"sentencizer\")\n",
    "    return nlp_fr\n",
    "    \n",
    "LABELS = ['par-dÃ©faut', 'ne-connais-pas', 'pas-sur-de-comprendre']\n",
    "\n",
    "def process(filepath):\n",
    "    doc = []    \n",
    "    with filepath.open('r') as f:\n",
    "        soup = BeautifulSoup(f.read())\n",
    "        for p in soup.find_all('text:p'):\n",
    "            text = p.getText() \n",
    "            target_words = re.findall(r\"\\[(.*?)\\]\", text)\n",
    "            \n",
    "            # skip target text that contains only stopwords\n",
    "            target_words = [f'{w}' for w in target_words if not is_stopword(w)]\n",
    "            # print(target_words)\n",
    "\n",
    "            word_dict = OrderedDict({word: LABELS[0] for word in target_words if word})\n",
    "            # print(dict)\n",
    "            # print(text)\n",
    "            text_spans = p.find_all('text:span')\n",
    "            for span in text_spans:\n",
    "                label = span.get('text:style-name')\n",
    "                # print(span.getText(), label)\n",
    "                if label in LABELS:\n",
    "                    target_text = span.getText()\n",
    "                    difficult_words = re.findall(r\"\\[(.*?)\\]\", target_text)\n",
    "                    for difficult_word in difficult_words:\n",
    "                        # print(difficult_word)\n",
    "                        word_dict[difficult_word] = label\n",
    "\n",
    "            text = re.sub(r'[\\[\\]]', '', text) # remove brackets\n",
    "            nlp_fr = get_sentence_segment_model()\n",
    "            nlp_doc = nlp_fr(text)\n",
    "\n",
    "            for word in word_dict:\n",
    "                \n",
    "                item = {}\n",
    "                item['annotator_file'] = filepath.stem.replace('-content','')\n",
    "                item['paragraph'] = text # remove brackets\n",
    "                \n",
    "                # add sentence-level text\n",
    "                item['sentence'] = ''\n",
    "                for sentence in nlp_doc.sents:\n",
    "                    # print(word, \" :: \", sentence, \" : \", word in sentence.text)\n",
    "                    if re.search(re.escape(word), sentence.text, re.IGNORECASE):\n",
    "                        item['sentence'] = sentence.text\n",
    "                        break\n",
    "\n",
    "                item['target'] = word\n",
    "                item['label'] = word_dict[word]\n",
    "\n",
    "                doc.append(item)\n",
    "    return doc\n",
    "    \n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "pool = multiprocessing.Pool(processes=multiprocessing.cpu_count())\n",
    "mapped_values = list(tqdm(pool.imap(process, filepaths), total=len(filepaths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame([value for values in mapped_values for value in values])\n",
    "data = data[data['sentence'] != ''] # drop rows with empty sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotator_file</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>sentence</th>\n",
       "      <th>target</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ak-1</td>\n",
       "      <td>Il s'agit d'une femme de 32 ans d'origine ghan...</td>\n",
       "      <td>Il s'agit d'une femme de 32 ans d'origine ghan...</td>\n",
       "      <td>s'agit</td>\n",
       "      <td>par-dÃ©faut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ak-1</td>\n",
       "      <td>Il s'agit d'une femme de 32 ans d'origine ghan...</td>\n",
       "      <td>Il s'agit d'une femme de 32 ans d'origine ghan...</td>\n",
       "      <td>d'une femme</td>\n",
       "      <td>par-dÃ©faut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ak-1</td>\n",
       "      <td>Il s'agit d'une femme de 32 ans d'origine ghan...</td>\n",
       "      <td>Il s'agit d'une femme de 32 ans d'origine ghan...</td>\n",
       "      <td>de 32 ans</td>\n",
       "      <td>par-dÃ©faut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ak-1</td>\n",
       "      <td>Il s'agit d'une femme de 32 ans d'origine ghan...</td>\n",
       "      <td>Il s'agit d'une femme de 32 ans d'origine ghan...</td>\n",
       "      <td>d'origine ghanÃ©enne enceinte de 14 semaines</td>\n",
       "      <td>par-dÃ©faut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ak-1</td>\n",
       "      <td>Il s'agit d'une femme de 32 ans d'origine ghan...</td>\n",
       "      <td>Elle prÃ©sente des vomissements depuis le dÃ©but...</td>\n",
       "      <td>prÃ©sente</td>\n",
       "      <td>par-dÃ©faut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51858</th>\n",
       "      <td>oi-99</td>\n",
       "      <td>De principe , un traitement antituberculeux pa...</td>\n",
       "      <td>De principe , un traitement antituberculeux pa...</td>\n",
       "      <td>a Ã©tÃ© instaurÃ©</td>\n",
       "      <td>par-dÃ©faut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51859</th>\n",
       "      <td>oi-99</td>\n",
       "      <td>De principe , un traitement antituberculeux pa...</td>\n",
       "      <td>De principe , un traitement antituberculeux pa...</td>\n",
       "      <td>pour 2 mois</td>\n",
       "      <td>par-dÃ©faut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51860</th>\n",
       "      <td>oi-99</td>\n",
       "      <td>De principe , un traitement antituberculeux pa...</td>\n",
       "      <td>De principe , un traitement antituberculeux pa...</td>\n",
       "      <td>relayÃ©</td>\n",
       "      <td>par-dÃ©faut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51861</th>\n",
       "      <td>oi-99</td>\n",
       "      <td>De principe , un traitement antituberculeux pa...</td>\n",
       "      <td>De principe , un traitement antituberculeux pa...</td>\n",
       "      <td>par une bithÃ©rapie</td>\n",
       "      <td>pas-sur-de-comprendre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51862</th>\n",
       "      <td>oi-99</td>\n",
       "      <td>De principe , un traitement antituberculeux pa...</td>\n",
       "      <td>De principe , un traitement antituberculeux pa...</td>\n",
       "      <td>pendant 4 mois</td>\n",
       "      <td>par-dÃ©faut</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51825 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      annotator_file                                          paragraph  \\\n",
       "0               ak-1  Il s'agit d'une femme de 32 ans d'origine ghan...   \n",
       "1               ak-1  Il s'agit d'une femme de 32 ans d'origine ghan...   \n",
       "2               ak-1  Il s'agit d'une femme de 32 ans d'origine ghan...   \n",
       "3               ak-1  Il s'agit d'une femme de 32 ans d'origine ghan...   \n",
       "4               ak-1  Il s'agit d'une femme de 32 ans d'origine ghan...   \n",
       "...              ...                                                ...   \n",
       "51858          oi-99  De principe , un traitement antituberculeux pa...   \n",
       "51859          oi-99  De principe , un traitement antituberculeux pa...   \n",
       "51860          oi-99  De principe , un traitement antituberculeux pa...   \n",
       "51861          oi-99  De principe , un traitement antituberculeux pa...   \n",
       "51862          oi-99  De principe , un traitement antituberculeux pa...   \n",
       "\n",
       "                                                sentence  \\\n",
       "0      Il s'agit d'une femme de 32 ans d'origine ghan...   \n",
       "1      Il s'agit d'une femme de 32 ans d'origine ghan...   \n",
       "2      Il s'agit d'une femme de 32 ans d'origine ghan...   \n",
       "3      Il s'agit d'une femme de 32 ans d'origine ghan...   \n",
       "4      Elle prÃ©sente des vomissements depuis le dÃ©but...   \n",
       "...                                                  ...   \n",
       "51858  De principe , un traitement antituberculeux pa...   \n",
       "51859  De principe , un traitement antituberculeux pa...   \n",
       "51860  De principe , un traitement antituberculeux pa...   \n",
       "51861  De principe , un traitement antituberculeux pa...   \n",
       "51862  De principe , un traitement antituberculeux pa...   \n",
       "\n",
       "                                            target                  label  \n",
       "0                                           s'agit             par-dÃ©faut  \n",
       "1                                      d'une femme             par-dÃ©faut  \n",
       "2                                        de 32 ans             par-dÃ©faut  \n",
       "3      d'origine ghanÃ©enne enceinte de 14 semaines             par-dÃ©faut  \n",
       "4                                         prÃ©sente             par-dÃ©faut  \n",
       "...                                            ...                    ...  \n",
       "51858                               a Ã©tÃ© instaurÃ©             par-dÃ©faut  \n",
       "51859                                  pour 2 mois             par-dÃ©faut  \n",
       "51860                                       relayÃ©             par-dÃ©faut  \n",
       "51861                           par une bithÃ©rapie  pas-sur-de-comprendre  \n",
       "51862                               pendant 4 mois             par-dÃ©faut  \n",
       "\n",
       "[51825 rows x 5 columns]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv( REPO_DIR / 'resources/dataset/data_all_annotators.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge all data based on annotators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(REPO_DIR / 'resources/dataset/data_all_annotators.csv')\n",
    "\n",
    "# data['label'] = data['label'].replace('pas-sur-de-comprendre', 'ne-connais-pas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>la voix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>les metabolites</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ã  type d'incontinence urinaire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>et de myopie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>au total trois mois</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9704</th>\n",
       "      <td>Ã  5 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9705</th>\n",
       "      <td>avec Ã©tude histologique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9706</th>\n",
       "      <td>lors de cette perfusion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9707</th>\n",
       "      <td>de la nicotine,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9708</th>\n",
       "      <td>de mÃ©tastase lymphonodale pelvienne</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9709 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        0\n",
       "0                                 la voix\n",
       "1                         les metabolites\n",
       "2          Ã  type d'incontinence urinaire\n",
       "3                            et de myopie\n",
       "4                     au total trois mois\n",
       "...                                   ...\n",
       "9704                                Ã  5 %\n",
       "9705              avec Ã©tude histologique\n",
       "9706              lors de cette perfusion\n",
       "9707                      de la nicotine,\n",
       "9708  de mÃ©tastase lymphonodale pelvienne\n",
       "\n",
       "[9709 rows x 1 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words = data['target'].unique()\n",
    "# unique_words = data[data['label'] == 'ne-connais-pas']['target'].unique()\n",
    "unique_words = set([word.lower() for word in unique_words])\n",
    "# pd.DataFrame(unique_words).to_csv('unique_words.csv', index=False)\n",
    "pd.DataFrame(unique_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9709/9709 [00:26<00:00, 359.71it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotator_file</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>sentence</th>\n",
       "      <th>target</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8642</th>\n",
       "      <td>ak-57</td>\n",
       "      <td>En novembre 2002 , Ã©tant donnÃ© la frÃ©quence du...</td>\n",
       "      <td>AprÃ¨s trois mois de ce rÃ©gime , on note une ne...</td>\n",
       "      <td>la voix</td>\n",
       "      <td>par-dÃ©faut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11890</th>\n",
       "      <td>ak-89</td>\n",
       "      <td>Une femme de 29 ans est victime d'agression se...</td>\n",
       "      <td>Du GHB est retrouvÃ© dans l'urine au taux de 4 ...</td>\n",
       "      <td>les metabolites</td>\n",
       "      <td>ne-connais-pas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>ak-10</td>\n",
       "      <td>Madame Nicole R., 63 ans, a Ã©tÃ© hospitalisÃ©e p...</td>\n",
       "      <td>A l'interrogatoire, il existait des troubles d...</td>\n",
       "      <td>Ã  type d'incontinence urinaire</td>\n",
       "      <td>par-dÃ©faut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7061</th>\n",
       "      <td>ak-51</td>\n",
       "      <td>Le patient est traitÃ© pour une acnÃ© vulgaire ,...</td>\n",
       "      <td>Il souffre par ailleurs d'allergies saisonniÃ¨r...</td>\n",
       "      <td>et de myopie</td>\n",
       "      <td>ne-connais-pas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8006</th>\n",
       "      <td>ak-54</td>\n",
       "      <td>Au jour 0 , le jeune patient reÃ§oit de l'acÃ©ta...</td>\n",
       "      <td>Les Ã©changes plasmatiques pour ce patient ont ...</td>\n",
       "      <td>au total trois mois</td>\n",
       "      <td>par-dÃ©faut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>ak-1</td>\n",
       "      <td>Lors de la premiÃ¨re visite mÃ©dicale Ã  11 semai...</td>\n",
       "      <td>Une perfusion intraveineuse continue de soluti...</td>\n",
       "      <td>Ã  5 %</td>\n",
       "      <td>par-dÃ©faut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11462</th>\n",
       "      <td>ak-82</td>\n",
       "      <td>Mme L . K 50 ans , diabÃ©tique , est admise dan...</td>\n",
       "      <td>La biopsie avec Ã©tude histologique confirme le...</td>\n",
       "      <td>avec Ã©tude histologique</td>\n",
       "      <td>par-dÃ©faut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8026</th>\n",
       "      <td>ak-54</td>\n",
       "      <td>Le patient devait recevoir quatre doses de rit...</td>\n",
       "      <td>La dose totale reÃ§ue lors de cette perfusion a...</td>\n",
       "      <td>lors de cette perfusion</td>\n",
       "      <td>par-dÃ©faut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3029</th>\n",
       "      <td>ak-28</td>\n",
       "      <td>Le 12 fÃ©vrier, Mademoiselle M., 36 ans, 64 kg,...</td>\n",
       "      <td>Du mÃ©probamate, de l'acÃ©promÃ©tazine, des benzo...</td>\n",
       "      <td>de la nicotine,</td>\n",
       "      <td>par-dÃ©faut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11473</th>\n",
       "      <td>ak-82</td>\n",
       "      <td>Mme L . K 50 ans , diabÃ©tique , est admise dan...</td>\n",
       "      <td>Le scanner abdomino-pelvien montre l'extension...</td>\n",
       "      <td>de mÃ©tastase lymphonodale pelvienne</td>\n",
       "      <td>ne-connais-pas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9709 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      annotator_file                                          paragraph  \\\n",
       "8642           ak-57  En novembre 2002 , Ã©tant donnÃ© la frÃ©quence du...   \n",
       "11890          ak-89  Une femme de 29 ans est victime d'agression se...   \n",
       "482            ak-10  Madame Nicole R., 63 ans, a Ã©tÃ© hospitalisÃ©e p...   \n",
       "7061           ak-51  Le patient est traitÃ© pour une acnÃ© vulgaire ,...   \n",
       "8006           ak-54  Au jour 0 , le jeune patient reÃ§oit de l'acÃ©ta...   \n",
       "...              ...                                                ...   \n",
       "69              ak-1  Lors de la premiÃ¨re visite mÃ©dicale Ã  11 semai...   \n",
       "11462          ak-82  Mme L . K 50 ans , diabÃ©tique , est admise dan...   \n",
       "8026           ak-54  Le patient devait recevoir quatre doses de rit...   \n",
       "3029           ak-28  Le 12 fÃ©vrier, Mademoiselle M., 36 ans, 64 kg,...   \n",
       "11473          ak-82  Mme L . K 50 ans , diabÃ©tique , est admise dan...   \n",
       "\n",
       "                                                sentence  \\\n",
       "8642   AprÃ¨s trois mois de ce rÃ©gime , on note une ne...   \n",
       "11890  Du GHB est retrouvÃ© dans l'urine au taux de 4 ...   \n",
       "482    A l'interrogatoire, il existait des troubles d...   \n",
       "7061   Il souffre par ailleurs d'allergies saisonniÃ¨r...   \n",
       "8006   Les Ã©changes plasmatiques pour ce patient ont ...   \n",
       "...                                                  ...   \n",
       "69     Une perfusion intraveineuse continue de soluti...   \n",
       "11462  La biopsie avec Ã©tude histologique confirme le...   \n",
       "8026   La dose totale reÃ§ue lors de cette perfusion a...   \n",
       "3029   Du mÃ©probamate, de l'acÃ©promÃ©tazine, des benzo...   \n",
       "11473  Le scanner abdomino-pelvien montre l'extension...   \n",
       "\n",
       "                                    target           label  \n",
       "8642                               la voix      par-dÃ©faut  \n",
       "11890                      les metabolites  ne-connais-pas  \n",
       "482         Ã  type d'incontinence urinaire      par-dÃ©faut  \n",
       "7061                          et de myopie  ne-connais-pas  \n",
       "8006                   au total trois mois      par-dÃ©faut  \n",
       "...                                    ...             ...  \n",
       "69                                   Ã  5 %      par-dÃ©faut  \n",
       "11462              avec Ã©tude histologique      par-dÃ©faut  \n",
       "8026               lors de cette perfusion      par-dÃ©faut  \n",
       "3029                       de la nicotine,      par-dÃ©faut  \n",
       "11473  de mÃ©tastase lymphonodale pelvienne  ne-connais-pas  \n",
       "\n",
       "[9709 rows x 5 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "\n",
    "def data_selection(word):\n",
    "    fd = data[data['target'].str.lower() == word]\n",
    "    labels = fd['label'].to_list()\n",
    "    \n",
    "    # majority approach\n",
    "    # counter = Counter(labels)\n",
    "    # label = 'ne-connais-pas' if counter['ne-connais-pas'] >= counter['par-dÃ©faut'] else 'par-dÃ©faut'\n",
    "\n",
    "    # at least one ne-connais-pas approach\n",
    "    label = 'ne-connais-pas' if 'ne-connais-pas' in labels else 'par-dÃ©faut'\n",
    "\n",
    "    d = fd.iloc[0]\n",
    "    d['label'] = label\n",
    "    return d\n",
    "\n",
    "pool = multiprocessing.Pool(processes=multiprocessing.cpu_count())\n",
    "new_data = list(tqdm(pool.imap(data_selection, unique_words), total=len(unique_words)))\n",
    "\n",
    "\n",
    "new_data = pd.DataFrame(new_data)\n",
    "new_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3482, 5)\n",
      "(6227, 5)\n"
     ]
    }
   ],
   "source": [
    "# count each label\n",
    "print(new_data[new_data['label'] == 'ne-connais-pas'].shape)\n",
    "print(new_data[new_data['label'] == 'par-dÃ©faut'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save final data\n",
    "new_data.drop('annotator_file', inplace=True, axis=1)\n",
    "new_data.to_csv(REPO_DIR / 'resources/dataset/data.csv', index=False)\n",
    "new_data.to_excel(REPO_DIR / 'resources/dataset/data.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "08327656ff96552322a71a64f5ff759da69de14cc072a1bce0d6912743ec3a15"
  },
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('dev': pyenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
